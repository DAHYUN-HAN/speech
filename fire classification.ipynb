{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, LSTM, Flatten, RepeatVector, Permute, Multiply, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'C:/Users/dahyun/speech/data/train2/final/'\n",
    "TEST_DATA_DIR = 'C:/Users/dahyun/speech/data/test2/final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NEGATIVE_DATA_DIR = 'C:/Users/dahyun/speech/data/train2/negative/'\n",
    "TEST_NEGATIVE_DATA_DIR = 'C:/Users/dahyun/speech/data/test2/negative/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_spectrograms = []\n",
    "train_mel_spectrograms = []\n",
    "train_mfccs = []\n",
    "train_y = []\n",
    "\n",
    "test_X = []\n",
    "test_spectrograms = []\n",
    "test_mel_spectrograms = []\n",
    "test_mfccs = []\n",
    "test_y = []\n",
    "\n",
    "pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i - a.shape[0])))\n",
    "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "#STFT한 것, CNN분석하기 위해 Spectogram으로 만든 것, MF한 것, mel-spectogram한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = librosa.load('C:/Users/dahyun/speech/data/train2/final/2_0.wav_fire_0.wav', sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TRAIN_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        #print(TRAIN_DATA_DIR + fname)\n",
    "        wav, sr = librosa.load(TRAIN_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        train_mfccs.append(padded_mfcc)\n",
    "        train_y.append('0')\n",
    "    except Exception as e:\n",
    "        #print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TRAIN_NEGATIVE_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TRAIN_NEGATIVE_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        train_mfccs.append(padded_mfcc)\n",
    "        train_y.append('1')\n",
    "    except Exception as e:\n",
    "        #print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TEST_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TEST_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        test_mfccs.append(padded_mfcc)\n",
    "        test_y.append('0')\n",
    "    except Exception as e:\n",
    "        #print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TEST_NEGATIVE_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TEST_NEGATIVE_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        test_mfccs.append(padded_mfcc)\n",
    "        test_y.append('1')\n",
    "    except Exception as e:\n",
    "        #print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mfccs (4615, 20, 40)\n",
      "train_y (4615, 2)\n",
      "test_mfccs (200, 20, 40)\n",
      "test_y (200, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_mfccs = np.array(train_mfccs)\n",
    "train_y = np.array(train_y)\n",
    "train_y = to_categorical(np.array(train_y))\n",
    "\n",
    "test_mfccs = np.array(test_mfccs)\n",
    "test_y = np.array(test_y)\n",
    "test_y = to_categorical(np.array(test_y))\n",
    "\n",
    "print('train_mfccs', train_mfccs.shape)\n",
    "print('train_y', train_y.shape)\n",
    "\n",
    "print('test_mfccs', test_mfccs.shape)\n",
    "print('test_y', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: (4615, 20, 40, 1)\n",
      "test X shape: (200, 20, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X_ex = np.expand_dims(train_mfccs, -1)\n",
    "test_X_ex = np.expand_dims(test_mfccs, -1)\n",
    "print('train X shape:', train_X_ex.shape)\n",
    "print('test X shape:', test_X_ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"data/dataset\", \"train_X.npy\"), train_X_ex)\n",
    "np.save(os.path.join(\"data/dataset\", \"train_y.npy\"), np.array(train_y))\n",
    "np.save(os.path.join(\"data/dataset\", \"test_X.npy\"), test_X_ex)\n",
    "np.save(os.path.join(\"data/dataset\", \"test_y.npy\"), np.array(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ex = np.load(os.path.join('data/dataset', 'train_X.npy'))\n",
    "train_y = np.load(os.path.join('data/dataset', 'train_y.npy'))\n",
    "test_X_ex = np.load(os.path.join('data/dataset', 'test_X.npy'))\n",
    "test_y = np.load(os.path.join('data/dataset', 'test_y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_X_ex, train_y = shuffle(train_X_ex, train_y, random_state=1523)\n",
    "test_X_ex, test_y = shuffle(test_X_ex, test_y, random_state=1523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 40, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 17, 37, 64)        1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                73760     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 74,914\n",
      "Trainable params: 74,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ip = Input(shape=train_X_ex[0].shape)\n",
    "m = Conv2D(64, kernel_size=(4,4), activation='relu')(ip)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "\n",
    "m=Flatten()(m)\n",
    "m=Dense(32, activation='relu')(m)\n",
    "op=Dense(2, activation='softmax')(m)\n",
    "\n",
    "model = Model(ip, op)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.7015 - accuracy: 0.8030 - val_loss: 0.9216 - val_accuracy: 0.8100\n",
      "Epoch 2/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4904 - accuracy: 0.8555 - val_loss: 0.8388 - val_accuracy: 0.8350\n",
      "Epoch 3/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4063 - accuracy: 0.8828 - val_loss: 0.7676 - val_accuracy: 0.8700\n",
      "Epoch 4/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.3436 - accuracy: 0.8992 - val_loss: 0.7122 - val_accuracy: 0.8950\n",
      "Epoch 5/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.2959 - accuracy: 0.9142 - val_loss: 0.6510 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.2585 - accuracy: 0.9239 - val_loss: 0.6398 - val_accuracy: 0.9100\n",
      "Epoch 7/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.9324 - val_loss: 0.5950 - val_accuracy: 0.9100\n",
      "Epoch 8/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.2048 - accuracy: 0.9385 - val_loss: 0.5911 - val_accuracy: 0.9150\n",
      "Epoch 9/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.9460 - val_loss: 0.5808 - val_accuracy: 0.9150\n",
      "Epoch 10/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1667 - accuracy: 0.9519 - val_loss: 0.5513 - val_accuracy: 0.9200\n",
      "Epoch 11/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1522 - accuracy: 0.9571 - val_loss: 0.5398 - val_accuracy: 0.9300\n",
      "Epoch 12/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1395 - accuracy: 0.9597 - val_loss: 0.5570 - val_accuracy: 0.9300\n",
      "Epoch 13/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1286 - accuracy: 0.9621 - val_loss: 0.5485 - val_accuracy: 0.9300\n",
      "Epoch 14/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.9651 - val_loss: 0.5298 - val_accuracy: 0.9300\n",
      "Epoch 15/15\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1106 - accuracy: 0.9688 - val_loss: 0.5096 - val_accuracy: 0.9350\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.000001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X_ex,\n",
    "                    train_y,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_X_ex, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEsCAYAAADjMlnoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb8ElEQVR4nO3de5wcZZ3v8c83CeF+yQUSCGTJgXA77AoYIBGMQDZABExkVRCOYkRHcbkjRjweQeT4woUjsIDKcNHsolxECYgKgRiMoEICZsFclMg1IRcIJASEEKZ/54+qCU02menpdE/10/N986rXdFdVV/0mzOs7zzz1PFWKCMzMLB29ii7AzMy6xsFtZpYYB7eZWWIc3GZmiXFwm5klxsFtZpYYB7dtNEmbS/qFpJWSfroRxzlZ0tRa1lYUSR+U9Jei67DmJI/j7jkknQScC+wFrAJmA/83Ih7ayON+CjgD+EBEvLOxdTY6SQEMj4gFRddiPZNb3D2EpHOBK4FvA4OAocD3gPE1OPw/AH/tCaFdCUl9iq7BmlxEeGnyBdgWeB34eAf7bEoW7C/my5XApvm2w4CFwHnAMmAxMDHf9k3gbWBNfo5TgYuAm8uOvSsQQJ/8/WeAp8la/c8AJ5etf6jscx8AZgIr868fKNv2IPAt4OH8OFOBgRv43trr/0pZ/ROADwN/BV4Bvla2/0HAH4AV+b7XAH3zbTPy7+WN/Ps9oez4k4AlwH+2r8s/s1t+jgPy9zsBLwGHFf2z4SXNxS3unmEUsBlwZwf7/G9gJLAf8D6y8Pp62fbBZL8AhpCF87WS+kXEhWSt+NsiYquIuLGjQiRtCfw7MC4itiYL59nr2a8/8Mt83wHAd4FfShpQtttJwERgB6Av8OUOTj2Y7N9gCPAN4HrgfwHvBz4I/B9Jw/J924BzgIFk/3ZjgC8BRMTofJ/35d/vbWXH70/210dL+Ykj4m9koX6zpC2AHwKTI+LBDuo12yAHd88wAHg5Ou7KOBm4OCKWRcRLZC3pT5VtX5NvXxMRvyJrbe5ZZT0lYF9Jm0fE4oiYs559jgGeioj/jIh3IuIWYD5wXNk+P4yIv0bEm8DtZL90NmQNWX/+GuBWslC+KiJW5eefS/YLi4h4LCL+mJ/3WeA64EMVfE8XRsTqvJ73iIjrgQXAI8COZL8ozari4O4ZlgMDO+l73Ql4ruz9c/m6tcdYJ/j/DmzV1UIi4g2y7oUvAosl/VLSXhXU017TkLL3S7pQz/KIaMtftwfr0rLtb7Z/XtIeku6RtETSa2R/UQzs4NgAL0XEW53scz2wL3B1RKzuZF+zDXJw9wx/AFaT9etuyItkf+a3G5qvq8YbwBZl7weXb4yI+yJiLFnLcz5ZoHVWT3tNi6qsqSu+T1bX8IjYBvgaoE4+0+HwLElbkV03uBG4KO8KMquKg7sHiIiVZP2610qaIGkLSZtIGifp3/LdbgG+Lml7SQPz/W+u8pSzgdGShkraFrigfYOkQZLG533dq8m6XErrOcavgD0knSSpj6QTgH2Ae6qsqSu2Bl4DXs//Gjhtne1Lgf/RxWNeBcyKiM+R9d3/YKOrtB7Lwd1DRMT/IxvD/XWyEQ0vAKcDU/JdLgFmAU8ATwKP5+uqOdf9wG35sR7jvWHbK6/jRbKRFh/ivwcjEbEcOJZsJMtyshEhx0bEy9XU1EVfJrvwuYrsr4Hb1tl+ETBZ0gpJn+jsYJLGA0fz7vd5LnCApJNrVrH1KJ6AY2aWGLe4zcwS4+A2M0uMg9vMLDEObjOzxDi4zcwS4+A2M0uMg9vMLDEObjOzxDi4zcwS4+A2M0uMg9vMLDEObjOzxDi4zcwS4+A2M0uMg9vMLDEObjOzxDi4zcwS4+A2M0uMg9vMLDEObjOzxDi4zcwS4+A2M0uMg9vMLDEObjOzGpN0k6Rlkv5ctq6/pPslPZV/7Zevl6R/l7RA0hOSDujs+A5uM7Pa+xFw9DrrvgpMi4jhwLT8PcA4YHi+tADf7+zgDm4zsxqLiBnAK+usHg9Mzl9PBiaUrf+PyPwR2E7Sjh0dv08Na621KLoAazySii7BGlBE1OIHo+LMkfQFstZxu9aIaO3kY4MiYnH+egkwKH89BHihbL+F+brFbEAjB7eZWUPKQ7qzoO7o8yGp6sapu0rMzICIqHip0tL2LpD867J8/SJgl7L9ds7XbZCD28wMaCuVKl6qdDdwSv76FOCusvWfzkeXjARWlnWprJc24rdHvTVsYVYc93Hb+tSij3tN2zsVZ84mvft0eD5JtwCHAQOBpcCFwBTgdmAo8BzwiYh4RdkP9TVko1D+DkyMiFkdHt/BbSlxcNv61CK4V79TeXBv2qfj4K43X5w0M4ON6bvudg5uMzOg5OA2M0uLW9xmZonZiNEi3c7BbWaGW9xmZsmJhAayObjNzIBSOrnt4DYzA3eVmJklxxcnzcwS4xa3mVliPAHHzCwxbnGbmSXGwwHNzBLj4YBmZokpeVSJmVlafHHSzCwxvjhpZpYYt7jNzBLjFreZWWLaHNxmZmlxi9vMLDEObjOzxPjipJlZYtziNjNLjIPbzCwxbeEp72ZmSfFNpszMEuOuEjOzxDi4zcwS4+GAZmaJcYvbzCwxbX6QgplZWvzMSTOzxKQ0HLBX0QWYmTWCiKh46YykcyTNkfRnSbdI2kzSMEmPSFog6TZJfaut1cFtZkbtglvSEOBMYERE7Av0Bk4EvgNcERG7A68Cp1Zbq4PbzIzs4mSlSwX6AJtL6gNsASwGjgDuyLdPBiZUW6uD28yM2rW4I2IRcDnwPFlgrwQeA1ZExDv5bguBIdXW6uA2MyObgFPpIqlF0qyypaX9OJL6AeOBYcBOwJbA0bWs1aNKzMzo2nDAiGgFWjew+Z+BZyLiJQBJPwcOAbaT1Cdvde8MLKq2Vre4zcyAiMqXTjwPjJS0hSQBY4C5wHTgY/k+pwB3VVurg9vMjK51lXQkIh4huwj5OPAkWc62ApOAcyUtAAYAN1Zbq7tKzMyo7ZT3iLgQuHCd1U8DB9Xi+A5uMzPSusmUu0oawAUXXMCoUaM49thj165bsWIFEydO5Mgjj2TixImsXLkSyH64LrnkEsaOHctxxx3HnDlziirbCnTUUUcxf/58nnrqKSZNmlR0OU2hljMn683B3QCOP/54brjhhvesa21tZdSoUUydOpVRo0bR2ppdwJ4xYwbPPvssU6dO5Vvf+hYXXXRRARVbkXr16sW1117LuHHj2GefffjkJz/J3nvvXXRZyatVH3d3cHA3gAMPPJBtt932PeumTZvGhAkTAJgwYQIPPPDAe9ZLYr/99uO1115j2bJl3V2yFeiggw5iwYIFPPPMM6xZs4Zbb72V8ePHF11W8qIL/xWtbn3ckvYiG4TePjtoEXB3RMyr1zmbyfLly9lhhx0A2H777Vm+fDkAS5cuZfDgwWv3Gzx4MEuXLl27rzW/IUOG8MILL6x9v3DhQg4++OACK2oODdCQrlhdWtySJgG3AgIezRcBt0j6aj3O2cwkkQ0HNbN6qfG9SuqqXl0lpwIHRsSlEXFzvlxKNhRmg3fEKp9G2t6n21MNGDBgbRfIsmXL6N+/PwCDBg1iyZIla/dbsmQJgwYNKqRGK8aiRYvYZZdd1r7feeedWbSo6kl4lnMfN5TI5uiva8d823pFRGtEjIiIES0tLRvarUc44ogjmDJlCgBTpkxhzJgx71kfEcyePZutt97a3SQ9zMyZMxk+fDi77rorm2yyCSeeeCJ333130WUlL6VRJfXq4z4bmCbpKaC9M24osDtwep3Omaxzzz2XRx99lFdffZXRo0dzxhln0NLSwtlnn80dd9zBTjvtxJVXXgnAhz70IX77298yduxYNt98c7797W8XW7x1u7a2Nk4//XTuu+8+evfuzU033cTcuXOLLit5jRDIlVK9ipXUi6xrpPzi5MyIaKvwEOn8K1q3cV+/rU9EbPQPxk8efrjizDnpkEMK/UGs26iSiCgBf6zX8c3MaqnUlk5b0VPezcxIq6vEwW1mhoPbzCw5Dm4zs8REycFtZpYUt7jNzBITDTCVvVIObjMz0rrJlIPbzAz3cZuZJcd93GZmiXFwm5klxsFtZpaYaPOoEjOzpLjFbWaWmIRy28FtZgZucZuZJcfBbWaWmJIvTpqZpcUtbjOzxDi4zcxS4+A2M0tLpNPF7eA2M4Mm6SqRtApo/06Uf438dUTENnWuzcys25Sa4UEKEbF1dxZiZlaklFrcvSrZSdKhkibmrwdKGlbfsszMuleUouKlM5K2k3SHpPmS5kkaJam/pPslPZV/7VdtrZ0Gt6QLgUnABfmqvsDN1Z7QzKwhRVS+dO4q4N6I2At4HzAP+CowLSKGA9Py91WppMX9UeAjwBsAEfEi4G4UM2sqEVHx0hFJ2wKjgRvz474dESuA8cDkfLfJwIRqa60kuN+OrNLIi9qy2pOZmTWqUikqXiS1SJpVtrSUHWoY8BLwQ0l/knRDnpuDImJxvs8SYFC1tVYyHPB2SdcB20n6PPBZ4PpqT2hm1oi68rDgiGgFWjewuQ9wAHBGRDwi6SrW6RaJiJBU9dXQToM7Ii6XNBZ4DdgD+EZE3F/tCc3MGlENR5UsBBZGxCP5+zvIgnuppB0jYrGkHYFl1Z6g0gk4TwKbk3WXPFntyczMGlWtgjsilkh6QdKeEfEXYAwwN19OAS7Nv95V7Tk6DW5JnwO+AfyGbPLN1ZIujoibqj2pmVmjqfE47jOAH0vqCzwNTCS7pni7pFOB54BPVHvwSlrc5wP7R8RyAEkDgN8DDm4zaxq1DO6ImA2MWM+mMbU4fiXBvRxYVfZ+Vb7OzKxpRFs6Myc7ulfJufnLBcAjku4i6+MeDzzRDbWZmXWblKa8d9Tibp9k87d8aVd1h7qZWaNqiuCOiG92ZyFmZkXqyjjuolUyqmR74CvA/wQ2a18fEUfUsS4zs26VUou7kinvPwbmk03j/CbwLDCzjjWZmXW7Wt2rpDtUEtwDIuJGYE1E/DYiPgu4tW1mTSVKpYqXolUyHHBN/nWxpGOAF4H+9SvJzKz7NdszJy/Jb1N4HnA1sA1wTl2rMjPrZo3QBVKpSm4ydU/+ciVweH3LMTMrRlMEt6Srefdhwf9NRJxZl4rMzArQFMENzOq2KszMClZqS6eTu6MJOJM3tM3MrNk0S4vbzKzncHCbmaUlodx2cJuZQZN0lRQ9qmTo0L3reXhL1BPPP190CdakmuUmUx5VYmY9RqkBprJXyqNKzMxokq6SdvltXScB++DbuppZs0oouCu9res8fFtXM2tiUYqKl6L5tq5mZmQN7kqXovm2rmZmNFkfN76tq5n1AE0xqqSdb+tqZj1BI/RdV6qSUSU/ZD0TcfK+bjOzptBsXSX3lL3eDPgoWT+3mVnzaKbgjoiflb+XdAvwUN0qMjMrQLO1uNc1HNih1oWYmRWp1NZEwS1pFe/t415CNpPSzKxpNFWLOyK27o5CzMyKlFJwdzpzUtK0StaZmaUsIipeitbR/bg3A7YABkrqByjftA0wpBtqMzPrNo0QyJXqqKvkC8DZwE7AY7wb3K8B19S3LDOz7tUUE3Ai4irgKklnRMTV3ViTmVm3q3VwS+pN9kCaRRFxrKRhwK3AALLG8Kci4u1qjl3J3QFLkrYrK6afpC9VczIzs0ZVhz7us8huid3uO8AVEbE78CpwarW1VhLcn4+IFe1vIuJV4PPVntDMrBHVMrgl7QwcA9yQvxfZ7bDvyHeZDEyottZKJuD0lqTIq82b/32rPaGZWSOqcVfJlcBXgPbh1AOAFRHxTv5+IRsxyKOSFve9wG2SxkgaA9ySrzMzaxpdaXFLapE0q2xpaT+OpGOBZRHxWL1qraTFPQloAU7L398PXF+vgszMitCV4YAR0Qq0bmDzIcBHJH2Y7MZ82wBXAdtJ6pO3uncGFlVba6ct7ogoRcQPIuJjEfExYC7ZAxXMzJpGlEoVLx0eJ+KCiNg5InYFTgR+ExEnA9OBj+W7nQLcVW2tlXSVIGl/Sf8m6VngYmB+tSc0M2tEUap8qdIk4FxJC8j6vG+s9kAdzZzcA/hkvrwM3AYoIvwUHDNrOvWYORkRDwIP5q+fBg6qxXE76uOeD/wOODYiFgBI8rMmzawppTTlvaOukuOBxcB0SdfnI0rUwf5mZslqiptMRcQUYIqkLYHxZPct2UHS94E7I2Jqt1RoZtYNSm3pPOW9klElb0TETyLiOLIhLH/CD1Iws2YTUflSsIpGlbSLiFcjojUixtSrIDOzIkQX/itaNc+cNDNrOo3Qd10pB7eZGRAbMUC7uzm4zcxwi9vMLDmlTqayNxIHt5kZ7ioxM0uPu0rMzNLSCMP8KuXgNjPDFyfNzJJTKrUVXULFHNxmZrjFbWaWHAe3mVliHNxmZqlxcJuZpSXwBBwzs6R4yruZWWLcx21mlhjfq8TMLDFucVvVLrvsEsaMOYzly19h7NiPAHDeeWdy5JFHUCqVWL78Fc477wKWLn2p4EqtO/3ijjuY9utfI4mhw4bxr+efz8Vf+QpvvfkmACtXrGD3Pfdk0sUXF1xpulIK7i49c9Lq76c/ncKnP93ynnXXXXcjRx01gXHjjmfatAc566wvFVSdFWH5yy/z6ylT+M73vscVN9xAqa2Nh6dP55Irr+Ty667j8uuuY4+99+bgQw8tutS0NevDgq3+Hn10FitWrHjPutdff2Pt6y222LwRfm6sm7W1tfH26tW0tbWxevVq+g0YsHbb3994gz/Pns1BhxxSYIXpK0VbxUvRur2rRNLEiPhhd583deeffxb/8i/jWbXqdU444ZSiy7FuNGDgQD7y8Y9z2kkn0XfTTfmn97+f/UaMWLv90Ycf5h/3358tttyywCrT566Sjn1zQxsktUiaJWnW66+v6MaSGt9ll13FyJFHMGXKL/jMZ04uuhzrRq+vWsXM3/+ea2++mdbbbmP1W28x44EH1m5/aPp0Dj388AIrbA4RUfFStLoEt6QnNrA8CQza0OciojUiRkTEiK222q4epSXvzjvvYdy4I4suw7rRE48/zg6DB7PtdtvRp08fDj70UP4yZw4Ar61cyYL58zlg5MiCq0xfSsFdr66SQcBRwKvrrBfw+zqds2ntuus/8OyzzwFw5JFH8Le/PV1wRdadBu6wA3+dN4/Vb71F30035ck//Ynd9tgDgD/MmMH7R46kb9++BVeZPo/jhnuArSJi9robJD1Yp3M2hauvvpxRow6iX7/teOSR6Xz3u9dw+OGj2W23YZRKJRYtepELLrio6DKtG+2x996MGj2a8087jd69ezNs990Ze8wxADw8fTofPfHEgitsDpHQlHc1QrN/fYYO3bsxC7NC/fLhqUWXYA3oH3fZRRt7jAMPHFdx5syc+euNPt/G8AQcMzPSGlXi4DYzw33cZmbJSanF7ZmTZmbUbjigpF0kTZc0V9IcSWfl6/tLul/SU/nXftXW6uA2MyN7kEKlSyfeAc6LiH2AkcC/StoH+CowLSKGA9Py91VxcJuZAUSp8qWjw0QsjojH89ergHnAEGA8MDnfbTIwodpSHdxmZkB04b/y23PkS8v6jilpV2B/4BFgUEQszjctoYNZ5J3xxUkzM7p2cTIiWoHWjvaRtBXwM+DsiHhNenfod0SEpKqvhjq4zcyo7agSSZuQhfaPI+Ln+eqlknaMiMWSdgSWVXt8d5WYmZGN46506YiypvWNwLyI+G7ZpruB9nsynwLcVW2tbnGbmUElo0UqdQjwKeBJSbPzdV8DLgVul3Qq8BzwiWpP4OA2M6N2XSUR8RDZnVDXZ0wtzuHgNjODhniWZKUc3GZmQOB7lZiZJSWle5U4uM3MqOnFybpzcJuZ4du6mpklx10lZmaJcXCbmaXGwW1mlpbAwW1mlpRSqa3oEirm4DYzw33cZmbJcXCbmSXGwW1mlhhPwDEzS41b3GZmaSm5xW1mlhZ3lZiZJcYXJ83MEuPgNjNLjIPbzCwx4SnvZmZp8U2mzMwS464SM7PEOLjNzBLjcdxmZolxi9vMLDGlklvcZmZpcYvbzCwtgVvcZmZJcR+3mVliHNxmZolxcJuZJabke5WYmaUlpRZ3r6ILMDNrCBGVL52QdLSkv0haIOmrtS7VwW1mRnZ3wEr/64ik3sC1wDhgH+CTkvapZa3uKjEzo6b3KjkIWBARTwNIuhUYD8yt1Qkc3GZm1HTK+xDghbL3C4GDa3VwaODgfv75eSq6hkYhqSUiWouuwxqLfy5qKyIqzhxJLUBL2arW7vx/4T7uNLR0vov1QP65KEhEtEbEiLKlPLQXAbuUvd85X1czDm4zs9qaCQyXNExSX+BE4O5anqBhu0rMzFIUEe9IOh24D+gN3BQRc2p5Dgd3GtyPaevjn4sGFRG/An5Vr+MrpdlCZmbmPm4zs+Q4uBtcvafOWnok3SRpmaQ/F12LFcPB3cC6Y+qsJelHwNFFF2HFcXA3trVTZyPibaB96qz1YBExA3il6DqsOA7uxra+qbNDCqrFzBqEg9vMLDEO7sZW96mzZpYeB3djq/vUWTNLj4O7gUXEO0D71Nl5wO21njpr6ZF0C/AHYE9JCyWdWnRN1r08c9LMLDFucZuZJcbBbWaWGAe3mVliHNxmZolxcJuZJcbBbR2S1CZptqQ/S/qppC024lg/kvSx/PUNHd0wS9Jhkj5QxTmelTSw0vXr7PN6F891kaQvd7VGs43l4LbOvBkR+0XEvsDbwBfLN0qq6ilKEfG5iJjbwS6HAV0ObrOewMFtXfE7YPe8Nfw7SXcDcyX1lnSZpJmSnpD0BQBlrsnvJ/4AsEP7gSQ9KGlE/vpoSY9L+i9J0yTtSvYL4py8tf9BSdtL+ll+jpmSDsk/O0DSVElzJN0AqLNvQtIUSY/ln2lZZ9sV+fppkrbP1+0m6d78M7+TtFdN/jXNquRnTlpF8pb1OODefNUBwL4R8Uwefisj4kBJmwIPS5oK7A/sSXYv8UHAXOCmdY67PXA9MDo/Vv+IeEXSD4DXI+LyfL+fAFdExEOShpLNJt0buBB4KCIulnQMUMksws/m59gcmCnpZxGxHNgSmBUR50j6Rn7s08me7fjFiHhK0sHA94AjqvhnNKsJB7d1ZnNJs/PXvwNuJOvCeDQinsnXHwn8U3v/NbAtMBwYDdwSEW3Ai5J+s57jjwRmtB8rIjZ0n+l/BvaR1jaot5G0VX6O4/PP/lLSqxV8T2dK+mj+epe81uVACbgtX38z8PP8HB8Aflp27k0rOIdZ3Ti4rTNvRsR+5SvyAHujfBVwRkTct85+H65hHb2AkRHx1npqqZikw8h+CYyKiL9LehDYbAO7R37eFev+G5gVyX3cVgv3AadJ2gRA0h6StgRmACfkfeA7Aoev57N/BEZLGpZ/tn++fhWwddl+U4Ez2t9I2i9/OQM4KV83DujXSa3bAq/mob0XWYu/XS+g/a+Gk8i6YF4DnpH08fwckvS+Ts5hVlcObquFG8j6rx/PH2B7Hdlfc3cCT+Xb/oPsjnbvEREvAS1k3RL/xbtdFb8APtp+cRI4ExiRX/ycy7ujW75JFvxzyLpMnu+k1nuBPpLmAZeS/eJo9wZwUP49HAFcnK8/GTg1r28OfnycFcx3BzQzS4xb3GZmiXFwm5klxsFtZpYYB7eZWWIc3GZmiXFwm5klxsFtZpYYB7eZWWL+P1XjgRmpZNPpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X_ex)\n",
    "y_pred = np.argmax(Y_pred,axis=1)\n",
    "\n",
    "matrix = confusion_matrix(np.argmax(test_y,axis=1), y_pred)\n",
    "sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"bone\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999762e-01, 1.93373140e-07],\n",
       "       [1.22036345e-05, 9.99987841e-01],\n",
       "       [6.26480952e-03, 9.93735254e-01],\n",
       "       [9.99993205e-01, 6.74153534e-06],\n",
       "       [6.67359927e-05, 9.99933243e-01],\n",
       "       [6.37970807e-04, 9.99362051e-01],\n",
       "       [3.52969823e-06, 9.99996424e-01],\n",
       "       [9.99999762e-01, 2.27059004e-07],\n",
       "       [5.44318138e-03, 9.94556785e-01],\n",
       "       [9.99998093e-01, 1.88393483e-06],\n",
       "       [1.00212685e-06, 9.99999046e-01],\n",
       "       [1.75849870e-02, 9.82415020e-01],\n",
       "       [1.29474048e-02, 9.87052619e-01],\n",
       "       [1.33933267e-02, 9.86606598e-01],\n",
       "       [9.99199808e-01, 8.00242648e-04],\n",
       "       [2.82441196e-03, 9.97175574e-01],\n",
       "       [9.99951363e-01, 4.86446734e-05],\n",
       "       [9.99014139e-01, 9.85896564e-04],\n",
       "       [9.99997377e-01, 2.67039240e-06],\n",
       "       [9.81403947e-01, 1.85960326e-02],\n",
       "       [9.99725997e-01, 2.74015969e-04],\n",
       "       [9.99932766e-01, 6.72501483e-05],\n",
       "       [9.99570906e-01, 4.29095147e-04],\n",
       "       [9.99990463e-01, 9.54105963e-06],\n",
       "       [9.99998450e-01, 1.53106942e-06],\n",
       "       [9.99999762e-01, 2.66296411e-07],\n",
       "       [1.25757679e-02, 9.87424195e-01],\n",
       "       [9.98412013e-01, 1.58800813e-03],\n",
       "       [9.99521732e-01, 4.78237751e-04],\n",
       "       [9.99990702e-01, 9.31377963e-06],\n",
       "       [1.00000000e+00, 3.46931515e-08],\n",
       "       [9.99998927e-01, 1.12401779e-06],\n",
       "       [2.90598744e-03, 9.97094035e-01],\n",
       "       [1.74713001e-04, 9.99825299e-01],\n",
       "       [9.96063173e-01, 3.93686350e-03],\n",
       "       [5.08465397e-04, 9.99491572e-01],\n",
       "       [9.99999881e-01, 7.08327690e-08],\n",
       "       [4.83698495e-05, 9.99951601e-01],\n",
       "       [3.96019267e-03, 9.96039748e-01],\n",
       "       [3.73452413e-03, 9.96265471e-01],\n",
       "       [7.79874995e-03, 9.92201209e-01],\n",
       "       [9.99999642e-01, 4.10120776e-07],\n",
       "       [9.99978304e-01, 2.16574172e-05],\n",
       "       [9.99872804e-01, 1.27135383e-04],\n",
       "       [2.83112764e-01, 7.16887236e-01],\n",
       "       [9.99918342e-01, 8.16930187e-05],\n",
       "       [1.00000000e+00, 7.27251015e-09],\n",
       "       [3.18933278e-03, 9.96810615e-01],\n",
       "       [9.74320352e-01, 2.56796405e-02],\n",
       "       [9.99855757e-01, 1.44199061e-04],\n",
       "       [9.19295073e-01, 8.07048976e-02],\n",
       "       [9.98623133e-01, 1.37685903e-03],\n",
       "       [9.99999166e-01, 7.97022381e-07],\n",
       "       [9.87117827e-01, 1.28821684e-02],\n",
       "       [9.99985218e-01, 1.47734736e-05],\n",
       "       [5.42203779e-04, 9.99457777e-01],\n",
       "       [4.59416551e-05, 9.99954104e-01],\n",
       "       [9.97892320e-01, 2.10775319e-03],\n",
       "       [9.99999404e-01, 6.40516646e-07],\n",
       "       [9.99958754e-01, 4.11851688e-05],\n",
       "       [9.99995232e-01, 4.79635673e-06],\n",
       "       [9.99982238e-01, 1.77462989e-05],\n",
       "       [2.07555768e-05, 9.99979258e-01],\n",
       "       [9.99999881e-01, 1.69027643e-07],\n",
       "       [1.38333552e-02, 9.86166716e-01],\n",
       "       [3.24287009e-03, 9.96757090e-01],\n",
       "       [9.64748397e-05, 9.99903560e-01],\n",
       "       [2.21287132e-06, 9.99997735e-01],\n",
       "       [2.59457827e-02, 9.74054158e-01],\n",
       "       [9.99949336e-01, 5.06572251e-05],\n",
       "       [2.18955218e-03, 9.97810423e-01],\n",
       "       [9.99891520e-01, 1.08468688e-04],\n",
       "       [9.99999762e-01, 2.40878109e-07],\n",
       "       [9.96422172e-01, 3.57780629e-03],\n",
       "       [9.99997616e-01, 2.35948983e-06],\n",
       "       [9.99981642e-01, 1.83124102e-05],\n",
       "       [9.99697924e-01, 3.02153057e-04],\n",
       "       [9.98666763e-01, 1.33327604e-03],\n",
       "       [9.99999642e-01, 4.17195480e-07],\n",
       "       [1.06360985e-05, 9.99989390e-01],\n",
       "       [9.99992967e-01, 7.05434832e-06],\n",
       "       [4.07691561e-02, 9.59230840e-01],\n",
       "       [1.36483341e-05, 9.99986410e-01],\n",
       "       [1.88425965e-05, 9.99981165e-01],\n",
       "       [9.79409670e-05, 9.99902010e-01],\n",
       "       [9.99823153e-01, 1.76884409e-04],\n",
       "       [1.00212685e-06, 9.99999046e-01],\n",
       "       [6.69838071e-01, 3.30161929e-01],\n",
       "       [9.99999881e-01, 1.05201259e-07],\n",
       "       [9.81320441e-01, 1.86795518e-02],\n",
       "       [9.99999762e-01, 2.35342156e-07],\n",
       "       [9.99999166e-01, 8.38450319e-07],\n",
       "       [2.71139741e-01, 7.28860259e-01],\n",
       "       [9.99982595e-01, 1.73803219e-05],\n",
       "       [5.02915054e-06, 9.99994993e-01],\n",
       "       [7.97648954e-06, 9.99992013e-01],\n",
       "       [1.62154566e-02, 9.83784556e-01],\n",
       "       [9.99965549e-01, 3.44931141e-05],\n",
       "       [1.66218057e-02, 9.83378172e-01],\n",
       "       [9.99997616e-01, 2.33377432e-06],\n",
       "       [2.44311034e-03, 9.97556925e-01],\n",
       "       [6.36583281e-05, 9.99936342e-01],\n",
       "       [9.99992967e-01, 7.07839308e-06],\n",
       "       [9.99998927e-01, 1.06741174e-06],\n",
       "       [9.99999762e-01, 2.49234091e-07],\n",
       "       [1.21752045e-03, 9.98782456e-01],\n",
       "       [9.99011517e-01, 9.88452812e-04],\n",
       "       [9.99994755e-01, 5.19325204e-06],\n",
       "       [8.07007484e-04, 9.99193013e-01],\n",
       "       [9.99975562e-01, 2.44304083e-05],\n",
       "       [9.99999404e-01, 5.49273864e-07],\n",
       "       [1.67083554e-02, 9.83291686e-01],\n",
       "       [1.00000000e+00, 7.85921461e-09],\n",
       "       [9.99972224e-01, 2.77756917e-05],\n",
       "       [9.99830246e-01, 1.69728795e-04],\n",
       "       [3.40845361e-02, 9.65915501e-01],\n",
       "       [9.99848127e-01, 1.51829183e-04],\n",
       "       [9.99999762e-01, 2.76645238e-07],\n",
       "       [1.23324222e-03, 9.98766780e-01],\n",
       "       [9.87814188e-01, 1.21858418e-02],\n",
       "       [9.75356460e-01, 2.46435571e-02],\n",
       "       [9.99988317e-01, 1.16515266e-05],\n",
       "       [1.08201741e-04, 9.99891758e-01],\n",
       "       [2.29223733e-04, 9.99770820e-01],\n",
       "       [9.99999881e-01, 1.37375906e-07],\n",
       "       [9.99899983e-01, 9.99876938e-05],\n",
       "       [6.60341904e-02, 9.33965802e-01],\n",
       "       [3.76325799e-04, 9.99623656e-01],\n",
       "       [9.99968171e-01, 3.18221209e-05],\n",
       "       [9.99999166e-01, 8.84256735e-07],\n",
       "       [9.99982357e-01, 1.76530921e-05],\n",
       "       [4.61358832e-05, 9.99953866e-01],\n",
       "       [9.99999285e-01, 7.72941348e-07],\n",
       "       [4.67910198e-04, 9.99532104e-01],\n",
       "       [1.24625862e-03, 9.98753786e-01],\n",
       "       [3.17945820e-03, 9.96820569e-01],\n",
       "       [9.99999881e-01, 1.22807776e-07],\n",
       "       [1.00000000e+00, 1.62351892e-08],\n",
       "       [9.99911308e-01, 8.87224887e-05],\n",
       "       [3.09615233e-03, 9.96903837e-01],\n",
       "       [5.16935438e-03, 9.94830668e-01],\n",
       "       [2.12185800e-01, 7.87814200e-01],\n",
       "       [9.99994993e-01, 4.99432235e-06],\n",
       "       [9.99888539e-01, 1.11489993e-04],\n",
       "       [2.19061658e-01, 7.80938387e-01],\n",
       "       [4.11707180e-04, 9.99588311e-01],\n",
       "       [9.99991775e-01, 8.21740741e-06],\n",
       "       [7.53346235e-02, 9.24665391e-01],\n",
       "       [9.99999404e-01, 5.76048137e-07],\n",
       "       [8.79606843e-01, 1.20393164e-01],\n",
       "       [1.46036292e-03, 9.98539686e-01],\n",
       "       [9.98229206e-01, 1.77083153e-03],\n",
       "       [2.61866546e-04, 9.99738157e-01],\n",
       "       [9.99997497e-01, 2.47052481e-06],\n",
       "       [3.51398689e-04, 9.99648571e-01],\n",
       "       [1.18170668e-04, 9.99881864e-01],\n",
       "       [1.68573009e-04, 9.99831438e-01],\n",
       "       [9.99998808e-01, 1.17942750e-06],\n",
       "       [1.38705411e-06, 9.99998569e-01],\n",
       "       [2.39906018e-03, 9.97600973e-01],\n",
       "       [9.99999166e-01, 8.43703333e-07],\n",
       "       [4.08615777e-03, 9.95913804e-01],\n",
       "       [7.68717437e-04, 9.99231339e-01],\n",
       "       [2.00941716e-03, 9.97990608e-01],\n",
       "       [1.00212685e-06, 9.99999046e-01],\n",
       "       [4.08758297e-06, 9.99995947e-01],\n",
       "       [9.99998450e-01, 1.56899739e-06],\n",
       "       [9.98560727e-01, 1.43926416e-03],\n",
       "       [1.60619263e-02, 9.83938038e-01],\n",
       "       [9.99999881e-01, 7.65356205e-08],\n",
       "       [2.82124442e-04, 9.99717891e-01],\n",
       "       [9.99981403e-01, 1.85378449e-05],\n",
       "       [2.59634078e-04, 9.99740303e-01],\n",
       "       [7.30009237e-03, 9.92699921e-01],\n",
       "       [1.22100422e-02, 9.87789989e-01],\n",
       "       [6.42155528e-01, 3.57844472e-01],\n",
       "       [9.99998450e-01, 1.60280956e-06],\n",
       "       [4.65705479e-03, 9.95342970e-01],\n",
       "       [9.99998927e-01, 1.09608118e-06],\n",
       "       [9.99999404e-01, 6.24601171e-07],\n",
       "       [2.39843648e-05, 9.99976039e-01],\n",
       "       [9.99998331e-01, 1.72380624e-06],\n",
       "       [9.99999762e-01, 1.86709002e-07],\n",
       "       [9.06680286e-01, 9.33196768e-02],\n",
       "       [2.78142747e-03, 9.97218609e-01],\n",
       "       [9.99999523e-01, 5.15518991e-07],\n",
       "       [9.99999642e-01, 4.01876605e-07],\n",
       "       [9.99999166e-01, 8.39775510e-07],\n",
       "       [8.38023052e-03, 9.91619706e-01],\n",
       "       [8.70387722e-03, 9.91296172e-01],\n",
       "       [9.97925639e-01, 2.07431009e-03],\n",
       "       [9.99841690e-01, 1.58231778e-04],\n",
       "       [9.99999523e-01, 4.79053256e-07],\n",
       "       [3.35371643e-02, 9.66462791e-01],\n",
       "       [9.99999881e-01, 6.32740509e-08],\n",
       "       [9.99999642e-01, 3.81577451e-07],\n",
       "       [9.96507823e-01, 3.49212158e-03],\n",
       "       [9.99943852e-01, 5.61075940e-05],\n",
       "       [1.17521232e-03, 9.98824775e-01],\n",
       "       [1.84972230e-02, 9.81502771e-01]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(train_X_ex)\n",
    "y_pred=np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
