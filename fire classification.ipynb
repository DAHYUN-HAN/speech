{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, LSTM, Flatten, RepeatVector, Permute, Multiply, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'C:/Users/dahyun/speech/data/train/final_audio/'\n",
    "TEST_DATA_DIR = 'C:/Users/dahyun/speech/data/test/final_audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NEGATIVE_DATA_DIR = 'C:/Users/dahyun/speech/data/train/negative/'\n",
    "TEST_NEGATIVE_DATA_DIR = 'C:/Users/dahyun/speech/data/test/negative/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_spectrograms = []\n",
    "train_mel_spectrograms = []\n",
    "train_mfccs = []\n",
    "train_y = []\n",
    "\n",
    "test_X = []\n",
    "test_spectrograms = []\n",
    "test_mel_spectrograms = []\n",
    "test_mfccs = []\n",
    "test_y = []\n",
    "\n",
    "pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i - a.shape[0])))\n",
    "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "#STFT한 것, CNN분석하기 위해 Spectogram으로 만든 것, MF한 것, mel-spectogram한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TRAIN_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TRAIN_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        train_mfccs.append(padded_mfcc)\n",
    "        train_y.append('0')\n",
    "    except Exception as e:\n",
    "        print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TRAIN_NEGATIVE_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TRAIN_NEGATIVE_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        train_mfccs.append(padded_mfcc)\n",
    "        train_y.append('1')\n",
    "    except Exception as e:\n",
    "        print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TEST_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TEST_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        test_mfccs.append(padded_mfcc)\n",
    "        test_y.append('0')\n",
    "    except Exception as e:\n",
    "        print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(TEST_NEGATIVE_DATA_DIR):\n",
    "    try:\n",
    "        if '.wav' not in fname or 'dima' in fname:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(TEST_NEGATIVE_DATA_DIR + fname)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(wav)\n",
    "        padded_mfcc = pad2d(mfcc, 40)\n",
    "        \n",
    "        test_mfccs.append(padded_mfcc)\n",
    "        test_y.append('1')\n",
    "    except Exception as e:\n",
    "        print(fname, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001,)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mfccs (726, 20, 40)\n",
      "train_y (726, 2)\n",
      "test_mfccs (155, 20, 40)\n",
      "test_y (155, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_mfccs = np.array(train_mfccs)\n",
    "train_y = np.array(train_y)\n",
    "train_y = to_categorical(np.array(train_y))\n",
    "\n",
    "test_mfccs = np.array(test_mfccs)\n",
    "test_y = np.array(test_y)\n",
    "test_y = to_categorical(np.array(test_y))\n",
    "\n",
    "print('train_mfccs', train_mfccs.shape)\n",
    "print('train_y', train_y.shape)\n",
    "\n",
    "print('test_mfccs', test_mfccs.shape)\n",
    "print('test_y', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: (726, 20, 40, 1)\n",
      "test X shape: (155, 20, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X_ex = np.expand_dims(train_mfccs, -1)\n",
    "test_X_ex = np.expand_dims(test_mfccs, -1)\n",
    "print('train X shape:', train_X_ex.shape)\n",
    "print('test X shape:', test_X_ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"data/dataset\", \"train_X.npy\"), train_X_ex)\n",
    "np.save(os.path.join(\"data/dataset\", \"train_y.npy\"), np.array(train_y))\n",
    "np.save(os.path.join(\"data/dataset\", \"test_X.npy\"), test_X_ex)\n",
    "np.save(os.path.join(\"data/dataset\", \"test_y.npy\"), np.array(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ex = np.load(os.path.join('data/dataset', 'train_X.npy'))\n",
    "train_y = np.load(os.path.join('data/dataset', 'train_y.npy'))\n",
    "test_X_ex = np.load(os.path.join('data/dataset', 'test_X.npy'))\n",
    "test_y = np.load(os.path.join('data/dataset', 'test_y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_X_ex, train_y = shuffle(train_X_ex, train_y, random_state=1523)\n",
    "test_X_ex, test_y = shuffle(test_X_ex, test_y, random_state=1523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 20, 40, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 17, 37, 64)        1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                73760     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 74,914\n",
      "Trainable params: 74,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ip = Input(shape=train_X_ex[0].shape)\n",
    "m = Conv2D(64, kernel_size=(4,4), activation='relu')(ip)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "\n",
    "m=Flatten()(m)\n",
    "m=Dense(32, activation='relu')(m)\n",
    "op=Dense(2, activation='softmax')(m)\n",
    "\n",
    "model = Model(ip, op)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2428 - accuracy: 0.5510 - val_loss: 1.5387 - val_accuracy: 0.6903\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8390 - accuracy: 0.6033 - val_loss: 1.2602 - val_accuracy: 0.7226\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.5015 - accuracy: 0.6556 - val_loss: 1.0329 - val_accuracy: 0.7613\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2291 - accuracy: 0.7107 - val_loss: 0.8406 - val_accuracy: 0.8065\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.9940 - accuracy: 0.7534 - val_loss: 0.6944 - val_accuracy: 0.8323\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.8151 - accuracy: 0.7796 - val_loss: 0.5685 - val_accuracy: 0.8323\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6628 - accuracy: 0.8209 - val_loss: 0.4595 - val_accuracy: 0.8452\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.8375 - val_loss: 0.3653 - val_accuracy: 0.8645\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8485 - val_loss: 0.2871 - val_accuracy: 0.8710\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8678 - val_loss: 0.2276 - val_accuracy: 0.9097\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2747 - accuracy: 0.9063 - val_loss: 0.1867 - val_accuracy: 0.9226\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2375 - accuracy: 0.9229 - val_loss: 0.1542 - val_accuracy: 0.9226\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2101 - accuracy: 0.9284 - val_loss: 0.1278 - val_accuracy: 0.9355\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1885 - accuracy: 0.9366 - val_loss: 0.1080 - val_accuracy: 0.9548\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1717 - accuracy: 0.9366 - val_loss: 0.0916 - val_accuracy: 0.9548\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.000001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X_ex,\n",
    "                    train_y,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_X_ex, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X_ex)\n",
    "y_pred = np.argmax(Y_pred,axis=1)\n",
    "\n",
    "matrix = confusion_matrix(np.argmax(test_y,axis=1), y_pred)\n",
    "sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"bone\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.67099285e-01, 1.32900700e-01],\n",
       "       [9.69332814e-01, 3.06671523e-02],\n",
       "       [9.99334618e-04, 9.99000728e-01],\n",
       "       [2.38106310e-01, 7.61893690e-01],\n",
       "       [4.11459216e-04, 9.99588549e-01],\n",
       "       [9.99975681e-01, 2.43556206e-05],\n",
       "       [7.58322421e-04, 9.99241710e-01],\n",
       "       [1.28027759e-05, 9.99987245e-01],\n",
       "       [1.18309073e-01, 8.81690979e-01],\n",
       "       [9.96801615e-01, 3.19837010e-03],\n",
       "       [9.98429477e-01, 1.57050055e-03],\n",
       "       [6.87726401e-03, 9.93122756e-01],\n",
       "       [9.99915004e-01, 8.49673524e-05],\n",
       "       [1.18309073e-01, 8.81690979e-01],\n",
       "       [3.32092866e-04, 9.99667883e-01],\n",
       "       [1.52685493e-01, 8.47314477e-01],\n",
       "       [6.33080432e-04, 9.99366939e-01],\n",
       "       [5.82766533e-01, 4.17233437e-01],\n",
       "       [7.90213817e-05, 9.99920964e-01],\n",
       "       [2.69980989e-02, 9.73001838e-01],\n",
       "       [9.11753356e-01, 8.82465690e-02],\n",
       "       [4.27288841e-03, 9.95727181e-01],\n",
       "       [2.58587718e-01, 7.41412222e-01],\n",
       "       [8.72971359e-05, 9.99912739e-01],\n",
       "       [8.76615405e-01, 1.23384602e-01],\n",
       "       [4.34805127e-03, 9.95652020e-01],\n",
       "       [9.99968290e-01, 3.16881778e-05],\n",
       "       [1.29510672e-03, 9.98704910e-01],\n",
       "       [7.33537506e-03, 9.92664635e-01],\n",
       "       [2.85579998e-04, 9.99714434e-01],\n",
       "       [9.99989390e-01, 1.06208327e-05],\n",
       "       [4.17955947e-04, 9.99581993e-01],\n",
       "       [4.63442811e-05, 9.99953628e-01],\n",
       "       [3.13735902e-02, 9.68626440e-01],\n",
       "       [9.96863842e-01, 3.13615473e-03],\n",
       "       [9.15345969e-04, 9.99084592e-01],\n",
       "       [8.98949862e-01, 1.01050198e-01],\n",
       "       [9.99869466e-01, 1.30465894e-04],\n",
       "       [9.99964952e-01, 3.50696755e-05],\n",
       "       [7.46519145e-05, 9.99925375e-01],\n",
       "       [3.86648090e-03, 9.96133566e-01],\n",
       "       [9.37534332e-01, 6.24657236e-02],\n",
       "       [4.83288988e-03, 9.95167136e-01],\n",
       "       [9.99827862e-01, 1.72156899e-04],\n",
       "       [1.57556921e-01, 8.42443109e-01],\n",
       "       [2.42299810e-01, 7.57700205e-01],\n",
       "       [9.83263791e-01, 1.67361870e-02],\n",
       "       [1.41540995e-05, 9.99985814e-01],\n",
       "       [8.20747554e-01, 1.79252446e-01],\n",
       "       [9.96942341e-01, 3.05760582e-03],\n",
       "       [4.14399074e-05, 9.99958515e-01],\n",
       "       [1.48910316e-04, 9.99851108e-01],\n",
       "       [2.94477749e-03, 9.97055173e-01],\n",
       "       [1.18309073e-01, 8.81690979e-01],\n",
       "       [5.38829993e-03, 9.94611740e-01],\n",
       "       [1.28465388e-02, 9.87153471e-01],\n",
       "       [2.96364993e-01, 7.03634977e-01],\n",
       "       [9.99547541e-01, 4.52423847e-04],\n",
       "       [2.61249897e-06, 9.99997377e-01],\n",
       "       [1.27344532e-03, 9.98726547e-01],\n",
       "       [9.44047511e-01, 5.59524633e-02],\n",
       "       [2.30888985e-02, 9.76911128e-01],\n",
       "       [9.99949098e-01, 5.09145393e-05],\n",
       "       [6.25534740e-05, 9.99937415e-01],\n",
       "       [9.99987841e-01, 1.21517924e-05],\n",
       "       [9.83981788e-01, 1.60182621e-02],\n",
       "       [9.98841584e-01, 1.15839962e-03],\n",
       "       [2.79585994e-03, 9.97204185e-01],\n",
       "       [7.52178894e-04, 9.99247849e-01],\n",
       "       [9.90500033e-01, 9.49993450e-03],\n",
       "       [3.02674307e-04, 9.99697328e-01],\n",
       "       [9.95199382e-01, 4.80065681e-03],\n",
       "       [9.84601140e-01, 1.53988665e-02],\n",
       "       [9.99608099e-01, 3.91940150e-04],\n",
       "       [5.80133754e-04, 9.99419928e-01],\n",
       "       [9.97528851e-01, 2.47113220e-03],\n",
       "       [9.98193443e-01, 1.80657266e-03],\n",
       "       [2.02217598e-05, 9.99979734e-01],\n",
       "       [9.99981761e-01, 1.82651638e-05],\n",
       "       [5.43776667e-04, 9.99456227e-01],\n",
       "       [5.19811991e-04, 9.99480188e-01],\n",
       "       [1.43239638e-02, 9.85676050e-01],\n",
       "       [9.77152288e-01, 2.28477530e-02],\n",
       "       [9.99596775e-01, 4.03264916e-04],\n",
       "       [9.99992847e-01, 7.18687852e-06],\n",
       "       [9.99952555e-01, 4.74884291e-05],\n",
       "       [7.33681209e-03, 9.92663145e-01],\n",
       "       [3.26928493e-05, 9.99967337e-01],\n",
       "       [1.12969276e-04, 9.99886990e-01],\n",
       "       [9.96983826e-01, 3.01611749e-03],\n",
       "       [9.97671783e-01, 2.32825195e-03],\n",
       "       [1.16141295e-04, 9.99883890e-01],\n",
       "       [7.71399168e-03, 9.92285967e-01],\n",
       "       [1.61745062e-03, 9.98382568e-01],\n",
       "       [4.67721343e-01, 5.32278657e-01],\n",
       "       [4.84398843e-05, 9.99951601e-01],\n",
       "       [5.23122121e-03, 9.94768858e-01],\n",
       "       [3.53908108e-04, 9.99646068e-01],\n",
       "       [1.47702194e-05, 9.99985218e-01],\n",
       "       [9.91680324e-01, 8.31961725e-03],\n",
       "       [1.26499531e-03, 9.98735011e-01],\n",
       "       [2.19184766e-03, 9.97808158e-01],\n",
       "       [9.99664307e-01, 3.35650780e-04],\n",
       "       [5.17630077e-04, 9.99482393e-01],\n",
       "       [2.00161822e-02, 9.79983866e-01],\n",
       "       [5.06863697e-04, 9.99493122e-01],\n",
       "       [9.91347611e-01, 8.65242817e-03],\n",
       "       [2.87819207e-02, 9.71218109e-01],\n",
       "       [1.32375350e-03, 9.98676240e-01],\n",
       "       [9.99891400e-01, 1.08547109e-04],\n",
       "       [8.38182390e-01, 1.61817610e-01],\n",
       "       [6.59211810e-06, 9.99993443e-01],\n",
       "       [9.99997139e-01, 2.83145664e-06],\n",
       "       [6.50055647e-01, 3.49944383e-01],\n",
       "       [9.97685790e-01, 2.31426302e-03],\n",
       "       [9.99707639e-01, 2.92312179e-04],\n",
       "       [9.90295589e-01, 9.70441103e-03],\n",
       "       [7.54390240e-01, 2.45609805e-01],\n",
       "       [9.99965072e-01, 3.49822294e-05],\n",
       "       [4.79111564e-04, 9.99520898e-01],\n",
       "       [6.11241937e-01, 3.88758063e-01],\n",
       "       [1.61242322e-04, 9.99838710e-01],\n",
       "       [1.95498377e-01, 8.04501653e-01],\n",
       "       [9.99648690e-01, 3.51269089e-04],\n",
       "       [8.21782742e-03, 9.91782188e-01],\n",
       "       [9.99998808e-01, 1.14973295e-06],\n",
       "       [9.95997667e-01, 4.00230754e-03],\n",
       "       [3.32684931e-06, 9.99996662e-01],\n",
       "       [5.29229990e-04, 9.99470770e-01],\n",
       "       [4.56194347e-03, 9.95438039e-01],\n",
       "       [9.99983788e-01, 1.61558255e-05],\n",
       "       [9.52333733e-02, 9.04766619e-01],\n",
       "       [3.29424604e-03, 9.96705830e-01],\n",
       "       [9.81097817e-01, 1.89021733e-02],\n",
       "       [9.22259808e-01, 7.77401254e-02],\n",
       "       [4.57302993e-03, 9.95426893e-01],\n",
       "       [5.96061170e-07, 9.99999404e-01],\n",
       "       [6.67283416e-01, 3.32716614e-01],\n",
       "       [2.99974072e-05, 9.99969959e-01],\n",
       "       [6.53444513e-05, 9.99934673e-01],\n",
       "       [4.19378048e-05, 9.99958038e-01],\n",
       "       [6.76978452e-05, 9.99932289e-01],\n",
       "       [9.99981880e-01, 1.81060441e-05],\n",
       "       [9.98127043e-01, 1.87295757e-03],\n",
       "       [7.29584515e-01, 2.70415485e-01],\n",
       "       [1.99266896e-03, 9.98007357e-01],\n",
       "       [1.98587120e-04, 9.99801457e-01],\n",
       "       [2.67192990e-01, 7.32806981e-01],\n",
       "       [9.94601488e-01, 5.39857754e-03],\n",
       "       [9.99859095e-01, 1.40924065e-04],\n",
       "       [9.99631047e-01, 3.68989917e-04],\n",
       "       [2.38772453e-04, 9.99761283e-01],\n",
       "       [2.64095055e-04, 9.99735892e-01],\n",
       "       [2.76470982e-05, 9.99972343e-01],\n",
       "       [1.58548892e-06, 9.99998450e-01]], dtype=float32)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(train_X_ex)\n",
    "y_pred=np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
